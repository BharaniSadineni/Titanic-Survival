# Titanic Survival Data Visualization

This project explores and visualizes the Titanic dataset to analyze survival patterns using Python and various data visualization techniques.

ğŸ“Œ **Project Overview**  
This repository contains an exploratory data analysis (EDA) and visualization of the Titanic dataset. The project focuses on:
- âœ”ï¸ Cleaning and preprocessing data
- âœ”ï¸ Handling missing values and outliers
- âœ”ï¸ Exploratory visualizations using Matplotlib and Seaborn
- âœ”ï¸ Statistical analysis (Chi-Square, ANOVA)
- âœ”ï¸ Feature engineering for improved model performance
- âœ”ï¸ Machine learning classification models

ğŸ“‚ **Dataset**  
The dataset used in this project is the Titanic dataset, which can be found at [Kaggle Titanic Dataset](https://www.kaggle.com/c/titanic). The dataset contains the following columns:
- **PassengerId:** Unique ID for each passenger
- **Survived:** Survival status (0 = No, 1 = Yes)
- **Pclass:** Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)
- **Name:** Name of the passenger
- **Sex:** Gender of the passenger
- **Age:** Age of the passenger
- **SibSp:** Number of siblings/spouses aboard
- **Parch:** Number of parents/children aboard
- **Ticket:** Ticket number
- **Fare:** Ticket fare
- **Cabin:** Cabin number
- **Embarked:** Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)

ğŸ›  **Technologies Used**  
- **Python**
- **Pandas, NumPy:** Data processing & analysis
- **Matplotlib, Seaborn:** Data visualization
- **Scikit-Learn:** Machine learning models
- **XGBoost:** Advanced classification

ğŸ” **Exploratory Data Analysis (EDA)**  
The project covers various insights, including:
- ğŸ“Š Survival rate by gender, class, and age
- ğŸ“‰ Correlation heatmap of key variables
- ğŸ“Œ Outlier detection & handling using IQR method
- ğŸ“ˆ Feature engineering (Title extraction, FamilySize, Age groups)

ğŸ¤– **Machine Learning Models**  
Several models were trained to predict survival, including:
- ğŸ”¹ **Logistic Regression** â€“ Accuracy: 82.1%
- ğŸ”¹ **Random Forest Classifier** â€“ Accuracy: 83.2%
- ğŸ”¹ **XGBoost Classifier** â€“ Accuracy: 83.8%
